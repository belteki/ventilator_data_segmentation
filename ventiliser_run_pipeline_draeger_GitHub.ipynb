{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pageheader_rose2_babies.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of ventilator recordings using `ventiliser` package\n",
    "\n",
    "#### Author:  Dr Gusztav Belteki and David Chong\n",
    "\n",
    "This notebook runs the Ventiliser package on a ventilator recording (_DG007_) downloaded from the Draeger Babylog VN500 neonatal ventilator. \n",
    "\n",
    "This the paper describing _Ventiliser_: David Chong, Colin J Morley & Gusztav Belteki: **Computational analysis of neonatal ventilator waveforms and loops**. *Pediatric Research*, in press. \n",
    "\n",
    "The _Ventiliser_ Python package presented in the paper can be downloaded from [here](https://github.com/barrinalo/Ventiliser).\n",
    "\n",
    "With questions and for more information please contact us: gbelteki@aol.com (Gusztav Belteki), dtwc3@cam.ac.uk (David Chong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ventiliser.Draeger import Draeger\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress chained assignment warning, it does not affect the result\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different set of recordings are in different folders\n",
    "\n",
    "DRIVE = 'ELEMENTS'\n",
    "# Directory on external drive to read the ventilation data from\n",
    "DIR_READ_1 = '/Volumes/%s/Raw_data/Draeger/service_evaluation_old' % DRIVE\n",
    "DIR_READ_2 = '/Volumes/%s/Raw_data/Draeger/service_evaluation_new' % DRIVE\n",
    "DIR_READ_3 = '/Volumes/%s/Raw_data/Draeger/ventilation_CO2_elimination' % DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordings to run the pipeline on\n",
    "recordings_selected = [ 'DG007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "freq = 100 \n",
    "# Sampling rate (Hz)\n",
    "\n",
    "flow_unit_converter = lambda x : x * 1000 / 60 / freq\n",
    "# freq is incorporated in flow_unit_converter, because it assumes the data from the ventilator is in L/min. \n",
    "# Each datapoint is converted to mL/sample point so that when one integrates the flows \n",
    "# in each breath one will get the volume in mL. \n",
    "\n",
    "correction_window = 6000\n",
    "# correction window is the window size (in data points) to perform averaging.\n",
    "\n",
    "def run_pipeline(recording):\n",
    "    \n",
    "    x = int(recording.split('_')[0][-3:].lstrip('0'))\n",
    "    if x <= 60:\n",
    "        PATH = DIR_READ_1\n",
    "    elif 60 < x <= 111:\n",
    "        PATH = DIR_READ_2\n",
    "    else:\n",
    "        PATH = DIR_READ_3\n",
    "    \n",
    "    DATA_DIR = os.path.join(PATH, recording)\n",
    "\n",
    "    tags = []\n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        if \"_fast_Unknown.csv\" in file: # Files containing 100 Hz data have this tag\n",
    "            tags.append(file)\n",
    "    print(tags, '\\n')\n",
    "\n",
    "    for tag in tags:\n",
    "        print(\"Processing \" + tag)\n",
    "        print(\"Start time:\", datetime.datetime.now())\n",
    "    \n",
    "        # Instantiate pipeline and load data and settings\n",
    "        print(\"Loading data and settings\")\n",
    "        pipeline = Draeger()\n",
    "        # Columns containing absolute time, pressure, flow, respectively\n",
    "        pipeline.load_data(os.path.join(DATA_DIR, tag), [0,4,5], \n",
    "            correction_window = correction_window, flow_unit_converter=flow_unit_converter)\n",
    "        if os.path.exists(os.path.join(DATA_DIR, tag[:-17] + \"_slow_Setting.csv\")):\n",
    "            pipeline.load_mapper_settings(os.path.join(DATA_DIR, tag[:-17] + \"_slow_Setting.csv\"))\n",
    "            \n",
    "        # Process\n",
    "        pipeline.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for recording in recordings_selected:\n",
    "    print(recording, '\\n')\n",
    "    run_pipeline(recording)\n",
    "    print('-' * 40)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
